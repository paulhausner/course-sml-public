{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nfrom matplotlib.patches import Arc\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 14/2.54, 10/2.54\nmatplotlib.font_manager.FontProperties(family='Helvetica',size=11);"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "# 9.1 Analysing happiness across countries"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "In this exercise, we will consider the data set `data/happy.csv` with data from the World Happiness Report. For details see: https://worldhappiness.report/ed/2019/changing-world-happiness/"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## Dataset\n\n`GDP per capita` is in terms of Purchasing Power Parity (PPP) adjusted to constant 2011 international dollars, taken from the World Development Indicators (WDI) released by the World Bank on November 14, 2018. The equation uses the natural log of GDP per capita, as this form fits the data significantly better than GDP per capita.\n\nThe time series of `healthy life expectancy` at birth are constructed based on data from the World Health Organization (WHO) Global Health Observatory data repository, with data available for 2005, 2010, 2015, and 2016. To match this report\u2019s sample period, interpolation and extrapolation are used. \n\n`Social support` is the national average of the binary responses (either 0 or 1) to the Gallup World Poll (GWP) question \u201cIf you were in trouble, do you have relatives or friends you can count on to help you whenever you need them, or not?\u201d\n\n`Freedom to make life choices` is the national average of binary responses to the GWP question \u201cAre you satisfied or dissatisfied with your freedom to choose what you do with your life?\u201d\n\n`Generosity` is the residual of regressing the national average of GWP responses to the question \u201cHave you donated money to a charity in the past month?\u201d on GDP per capita.\n\n`Perceptions of corruption` are the average of binary answers to two GWP questions: \u201cIs corruption widespread throughout the government or not?\u201d and \u201cIs corruption widespread within businesses or not?\u201d Where data for government corruption are missing, the perception of business corruption is used as the overall corruption-perception measure."}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## a)\nLoad and familiarize yourself with the data set. We rename them because statsmodels needs variables to not include spaces."}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": []}, "outputs": [], "source": "#Read in the data\n#happy = pd.read_csv(\"data/happy.csv\",delimiter=';') \nhappy = pd.read_csv('https://uu-sml.github.io/course-sml-public/data/happy.csv', delimiter=';')\nhappy.head()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "happy.rename(columns = {'Social support':'SocialSupport'}, inplace = True) \nhappy.rename(columns = {'Life Ladder': 'LifeLadder'}, inplace = True) \nhappy.rename(columns = {'Perceptions of corruption':'Corruption'}, inplace = True) \nhappy.rename(columns = {'Log GDP per capita': 'LogGDP'}, inplace = True) \nhappy.rename(columns = {'Healthy life expectancy at birth': 'LifeExp'}, inplace = True) \nhappy.rename(columns = {'Freedom to make life choices': 'Freedom'}, inplace = True) \n\n#In this exercise we will just analyse one year. 2017.\ndf=happy.loc[happy['Year'] == 2017]\ndf=df.dropna()\ndf.head()"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## b)\nThe code below fits a linear regression model to predict life ladder (happiness) as a function of social support. Edit the code to fit a third order polynomial. What model would you suggest to use?"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Fit model.\nmodel_fit=smf.ols(formula='LifeLadder ~  SocialSupport - 1 ', data=df).fit()\nprint(model_fit.summary())        \nb=model_fit.params"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Compute predictions.\nx=np.arange(0.4,1,step=0.01)\ny=b[0]*x"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Fit model polynomial\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Compute predictions.\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Plot social support and life ladder data.\nfig,ax=plt.subplots(num=1)\nax.plot(  'SocialSupport','LifeLadder', data=df, linestyle='none', markersize=4, marker='o', color='grey')\ncountries=['United Kingdom','Croatia','Benin','Finland','Afghanistan']\nfor country in countries:\n    ci=np.where(df['Country name']==country)[0][0]\n    ax.plot(  df.iloc[ci]['SocialSupport'],df.iloc[ci]['LifeLadder'], linestyle='none', markersize=6, marker='o', color='black')\n    if country=='United Kingdom':\n        ax.text(  df.iloc[ci]['SocialSupport']-0.17,df.iloc[ci]['LifeLadder']+0.05,  country)\n    else:\n        ax.text(  df.iloc[ci]['SocialSupport']+0.005,df.iloc[ci]['LifeLadder']+0.05,  country) \nax.set_xticks(np.arange(0,1.2,step=0.2))\nax.set_yticks(np.arange(11,step=2))\nax.set_ylabel('Life Satisfaction (y)')\nax.set_xlabel('Social support (s)')\n\n#Plot model.\nax.plot(x, y, linestyle='-', color='black')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_ylim(2,8)\nax.set_xlim(0.4,1.05) \nplt.show()"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## c)\nThe code below fits a linear regression model to predict life ladder (happiness) as a linear function of six variables. Use AIC as a manual tool to investigate what the best model is combining these factors."}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "factors =['LogGDP', 'SocialSupport', 'LifeExp',  'Freedom', 'Generosity', 'Corruption']\n\n#Combine factors to string 'factor1 + factor2 + factor3 + ...'\nregfactors = ' + '.join(factors)\n\n#Regression model over all the data, so use happy NOT df\nmodel_fit=smf.ols(formula='LifeLadder ~ ' + regfactors, data=df).fit()\nprint(model_fit.summary())     \nb=model_fit.params"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## d)\nWrite an automated code to find the model with the smallest AIC= (loglikelihood - num factors)"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": ""}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "The best model for five factors is:\n```\nLoglikelihood - 5 = -110.5140\n```\n\nWith parameters:\n\n|Parameter|Value|\n|---|---|\n|Intercept |        50.179034|\n|LifeExp |          -2.267705|\n|Freedom |           1.761611|\n|LifeExp2 |          0.034706|\n|SocialSupport3 |    2.351361|\n|LifeExp3 |         -0.000170|\n\nThis can very likely be improved on."}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "# 9.2 Analysing goals in football"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "In this exercise, we will consider the data set `data/shots.csv`. This is a collection of all shots and goals in the English premier league for one season. See: https://figshare.com/articles/dataset/Events/7770599"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## Data\n'Goal' 1 if a goal, 0 if not a goal\n'X' x-location along long side of pitch in co-ordinates (0-100)\n'Y' y-location along short side of pitch (where goal is) in co-ordinates (0-100)\n'Distance' is distance (in metres) from middle of goal.\n'Angle' is of a triangle created fom the shot point to the goal mouth (as descibed in lectures)."}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Load data for all shots\n#shots_model=pd.read_csv('data/shots.csv')\nshots_model = pd.read_csv('https://uu-sml.github.io/course-sml-public/data/shots.csv')\nshots_model.head()"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "Function for plotting goal mouth "}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "def createGoalMouth():\n    #Adopted from FC Python\n    #Create figure\n    fig=plt.figure()\n    ax=fig.add_subplot(1,1,1)\n\n    linecolor='black'\n\n    #Pitch Outline & Centre Line\n    plt.plot([0,65],[0,0], color=linecolor)\n    plt.plot([65,65],[50,0], color=linecolor)\n    plt.plot([0,0],[50,0], color=linecolor)\n    \n    #Left Penalty Area\n    plt.plot([12.5,52.5],[16.5,16.5],color=linecolor)\n    plt.plot([52.5,52.5],[16.5,0],color=linecolor)\n    plt.plot([12.5,12.5],[0,16.5],color=linecolor)\n    \n    #Left 6-yard Box\n    plt.plot([41.5,41.5],[5.5,0],color=linecolor)\n    plt.plot([23.5,41.5],[5.5,5.5],color=linecolor)\n    plt.plot([23.5,23.5],[0,5.5],color=linecolor)\n    \n    #Goal\n    plt.plot([41.5-5.34,41.5-5.34],[-2,0],color=linecolor)\n    plt.plot([23.5+5.34,41.5-5.34],[-2,-2],color=linecolor)\n    plt.plot([23.5+5.34,23.5+5.34],[0,-2],color=linecolor)\n    \n    #Prepare Circles\n    leftPenSpot = plt.Circle((65/2,11),0.8,color=linecolor)\n    \n    #Draw Circles\n    ax.add_patch(leftPenSpot)\n    \n    #Prepare Arcs\n    leftArc = Arc((32.5,11),height=18.3,width=18.3,angle=0,theta1=38,theta2=142,color=linecolor)\n    \n    #Draw Arcs\n    ax.add_patch(leftArc)\n    \n    #Tidy Axes\n    plt.axis('off')\n    \n    return fig,ax"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## a)\nThe code plot the frequency of the data. "}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Two dimensional histogram\nH_Shot=np.histogram2d(shots_model['X'], shots_model['Y'],bins=50,range=[[0, 100],[0, 100]])\ngoals_only=shots_model[shots_model['Goal']==1]\nH_Goal=np.histogram2d(goals_only['X'], goals_only['Y'],bins=50,range=[[0, 100],[0, 100]])\n\n#Plot the number of shots from different points\n(fig,ax) = createGoalMouth()\npos=ax.imshow(H_Shot[0], extent=[-1,66,104,-1], aspect='auto',cmap=plt.cm.Reds)\nfig.colorbar(pos, ax=ax)\nax.set_title('Number of shots')\nplt.xlim((-1,66))\nplt.ylim((-3,35))\nplt.tight_layout()\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Plot the number of GOALS from different points\n(fig,ax) = createGoalMouth()\npos=ax.imshow(H_Goal[0], extent=[-1,66,104,-1], aspect='auto',cmap=plt.cm.Reds)\nfig.colorbar(pos, ax=ax)\nax.set_title('Number of goals')\nplt.xlim((-1,66))\nplt.ylim((-3,35))\nplt.tight_layout()\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Plot the probability of scoring from different points\n(fig,ax) = createGoalMouth()\npos=ax.imshow(H_Goal[0]/H_Shot[0], extent=[-1,66,104,-1], aspect='auto',cmap=plt.cm.Reds,vmin=0, vmax=0.5)\nfig.colorbar(pos, ax=ax)\nax.set_title('Proportion of shots resulting in a goal')\nplt.xlim((-1,66))\nplt.ylim((-3,35))\nplt.tight_layout()\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## b)\nThe code below plots how shot angle determine probability of scoring. It fits a logistic regression model and compares it to data. Make a similar plot for distance to goal. See what happens when you add distance squared."}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Look at frequencies of goals as function of angle.\nshotcount_dist=np.histogram(shots_model['Angle']*180/np.pi,bins=40,range=[0, 150])\ngoalcount_dist=np.histogram(goals_only['Angle']*180/np.pi,bins=40,range=[0, 150])\nprob_goal=np.divide(goalcount_dist[0],shotcount_dist[0])\nangle=shotcount_dist[1]\ntheangle= (angle[:-1] + angle[1:])/2\n\n#Make single variable model of angle\n#Using logistic regression we find the optimal values of b\ntest_model = smf.glm(formula=\"Goal ~ Angle\" , data=shots_model, \n                     family=sm.families.Binomial()).fit()\nprint(test_model.summary())        \nb=test_model.params\nxGprob=1/(1+np.exp(-b[0]-b[1]*theangle*np.pi/180)) \n\nfig,ax=plt.subplots(num=1)\nax.plot(theangle, prob_goal, linestyle='none', marker= '.', markerSize= 12, color='black')\nax.plot(theangle, xGprob, linestyle='solid', color='black')\nax.set_ylabel('Probability chance scored')\nax.set_xlabel(\"Shot angle (degrees)\")\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Show empirically how distance from goal predicts probability of scoring\n#Make single variable model of distance\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Adding distance squared\n"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## c)\nBy setting `model_variables` in the code below you can test different features. Investigate manually which parameters work best. "}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Adding even more variables to the model.\nsquaredX = shots_model['X']**2\nshots_model = shots_model.assign(X2=squaredX)\nsquaredC = shots_model['C']**2\nshots_model = shots_model.assign(C2=squaredC)\nAX = shots_model['Angle']*shots_model['X']\nshots_model = shots_model.assign(AX=AX)\n\n# A general model for fitting goal probability\n# List the model variables you want here\nmodel_variables = ['Distance']\n\n#Combine factors to string 'factor1 + factor2 + factor3 + ...'\nmodel = ' + '.join(model_variables)\n\n#Fit the model\ntest_model = smf.glm(formula=\"Goal ~ \" + model, data=shots_model,\n                     family=sm.families.Binomial()).fit()\nprint(test_model.summary())\nb=test_model.params"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Return xG value for more general model\ndef calculate_xG(sh):    \n   bsum=b[0]\n   for i,v in enumerate(model_variables):\n       bsum=bsum+b[i+1]*sh[v]\n   xG = 1/(1+np.exp(-bsum)) \n   return xG\n\n#Add an xG to my dataframe\nxG=shots_model.apply(calculate_xG, axis=1) \nshots_model = shots_model.assign(xG=xG)\n\n#Create a 2D map of xG\npgoal_2d=np.zeros((65,65))\nfor x in range(65):\n    for y in range(65):\n        sh=dict()\n        a = np.arctan(7.32 *x /(x**2 + abs(y-65/2)**2 - (7.32/2)**2))\n        if a<0:\n            a = np.pi + a\n        sh['Angle'] = a\n        sh['Distance'] = np.sqrt(x**2 + abs(y-65/2)**2)\n        sh['D2'] = x**2 + abs(y-65/2)**2\n        sh['X'] = x\n        sh['AX'] = x*a\n        sh['X2'] = x**2\n        sh['C'] = abs(y-65/2)\n        sh['C2'] = (y-65/2)**2\n        \n        pgoal_2d[x,y] =  calculate_xG(sh)\n\n(fig,ax) = createGoalMouth()\npos=ax.imshow(pgoal_2d, extent=[-1,65,65,-1], aspect='auto',cmap=plt.cm.Reds,vmin=0, vmax=0.3)\nfig.colorbar(pos, ax=ax)\nax.set_title('Probability of goal')\nplt.xlim((0,66))\nplt.ylim((-3,35))\nplt.gca().set_aspect('equal', adjustable='box')\nplt.show()"}], "metadata": {"@webio": {"lastCommId": null, "lastKernelId": null}, "celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}